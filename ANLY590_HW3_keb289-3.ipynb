{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLY590 HW3_keb289.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj6oT6AEM4f2",
        "colab_type": "text"
      },
      "source": [
        "#**ANLY590 Homework 3** \n",
        "**Kate Bosshart (keb289@georgetown.edu) | Due 06DEC2019**\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3ZRLQOiK74Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3d8df1e5-4c68-408b-bf06-74dfc45f8434"
      },
      "source": [
        "!pip install tensorflow==1.7\n",
        "!pip install tensorflow_hub"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.7 in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (0.33.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (1.17.4)\n",
            "Requirement already satisfied: tensorboard<1.8.0,>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (1.7.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.7) (42.0.1)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7) (0.9999999)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7) (1.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7) (0.16.0)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.17.4)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub) (42.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKV_WlhZLR6-",
        "colab_type": "code",
        "outputId": "51bbb774-effe-4baf-b63e-028da79934ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.7.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEEvabCnLIK1",
        "colab_type": "code",
        "outputId": "89e624e9-fdf2-4733-be24-d7770d75144f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras import regularizers, models, layers, optimizers, callbacks \n",
        "from keras import backend as K\n",
        "from keras.datasets import fashion_mnist \n",
        "from keras.utils import to_categorical, np_utils\n",
        "from keras.layers import Activation, Flatten, Input, Dense, Conv1D, Conv2D, Dropout, MaxPooling2D, UpSampling2D, RepeatVector\n",
        "from keras.layers import LSTM, Embedding\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import math\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os, time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "from google.colab import files, drive\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import logging\n",
        "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpdXwXNkMTSk",
        "colab_type": "text"
      },
      "source": [
        "### **1. Autoencoder**\n",
        "\n",
        "A convolutional autoencoder is a particular flavor of autoencoder where we use convolutional layers instead of Dense layers. We have previously applied autoencoders to images using only Dense layers and the result worked fairly well. However, the local spatial correlations of images imply that we should be able to do better using convolutional layers instead of Dense layers.\n",
        "Build and fit a convolutional autoencoder for the Fashion MNIST dataset. The components of this network will be many of the same pieces weâ€™ve used with convolutional classification networks: Conv2D, MaxPooling, and so on. The encoder part of the network should run the input image through a few convolutional layers of your choice. The decoder part of the network will utilize UpSampling2D to get the representation back to the original image size.\n",
        "\n",
        "An example to guide your thinking can be found toward the bottom of this post https://blog.keras.io/building-autoencoders-in-keras.html. DO NOT JUST COPY THIS CODE AND TURN IT IN. BE CREATIVE, COME UP WITH YOUR OWN VARIATION.\n",
        "\n",
        "\n",
        "After training your network, visualize some examples of input images and their decoded reconstruction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOZdp_x7URLE",
        "colab_type": "text"
      },
      "source": [
        "***Prep the MNIST Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0hr7O0rMRbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT THE DATA\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhTpXkUuMZtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREP THE DATA\n",
        "## flatten the 28x28 images into vectors of size 784\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  \n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s30GdNvEMbn9",
        "colab_type": "code",
        "outputId": "f2d29b6f-df4b-4146-c0d1-6937af0d5f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Confirm we have the flattened vectors of size 784\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "# Dim of image is 28x28x1 - which gives us the flattened 784 pixels"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl8XKU3oMdNr",
        "colab_type": "code",
        "outputId": "676567c5-4449-4b84-b910-a3fe05ad23fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Placeholder input image\n",
        "input_img = Input(shape=(28,28,1))\n",
        "\n",
        "print(input_img.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElhER0V5UYll",
        "colab_type": "text"
      },
      "source": [
        "***Build & fit a convolutional autoencoder***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4Ek4GiMetS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENCODER\n",
        "## Encoder should run input image thru few convolutional layers of your choice\n",
        "x = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "# \"Encoded\" is the encoded representation of the input\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofaaV6ZeMhLk",
        "colab_type": "code",
        "outputId": "72afc8b1-a10c-4082-e895-41586e83bc8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "print(encoded.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 2, 2, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcVuLum5MjF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DECODER\n",
        "## Decoder will utilize UpSampling2D to get representation back to original image size.\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "# \"Decoded\" reverts the encoded representation back to the shape of the input\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG-gUFHfMlkx",
        "colab_type": "code",
        "outputId": "f7fffd5f-ec60-4af6-8acd-394afa8764b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# After going thru the Decoder, the representation is (28, 28, 1) - same as our original image\n",
        "print(decoded.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSN1HnkIMppO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "b4daf417-784b-4346-f5ce-8088756f1da9"
      },
      "source": [
        "# Combine into a model that maps input to its encoded representation\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Configure model w per-pixel binary crossentropy loss & Adadelta optimizer:\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 8)           1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 2, 2, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 4, 4, 16)          1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_11 (UpSampling (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_12 (UpSampling (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 17,425\n",
            "Trainable params: 17,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anXCu64OkK62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "63dde415-49de-40a8-f5a0-78a5e89d4718"
      },
      "source": [
        "# Incorporate early stopping \n",
        "from keras.callbacks import EarlyStopping  \n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')\n",
        "\n",
        "# Train model\n",
        "history = autoencoder.fit(x_train, \n",
        "                          x_train, \n",
        "                          epochs=25, \n",
        "                          batch_size= 135, \n",
        "                          shuffle = True, \n",
        "                          validation_data=(x_test, x_test), \n",
        "                          callbacks=[early_stopping])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 199s 3ms/step - loss: 0.5241 - val_loss: 0.4107\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 198s 3ms/step - loss: 0.3967 - val_loss: 0.3970\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 196s 3ms/step - loss: 0.3739 - val_loss: 0.3576\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 196s 3ms/step - loss: 0.3998 - val_loss: 0.4290\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 196s 3ms/step - loss: 0.4187 - val_loss: 0.4188\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 195s 3ms/step - loss: 0.4169 - val_loss: 0.4540\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 194s 3ms/step - loss: 0.4140 - val_loss: 0.4136\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 194s 3ms/step - loss: 0.4094 - val_loss: 0.4016\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 195s 3ms/step - loss: 0.4330 - val_loss: 0.4347\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 195s 3ms/step - loss: 0.4299 - val_loss: 0.4174\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XclvX-i0Bbjm",
        "colab_type": "text"
      },
      "source": [
        "The model is oscelating and having trouble finding the minima. Need to try again with a smaller step size to see if that will help."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTpR0mXfBkXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0472c000-749a-49ce-823b-0ecd944df2a7"
      },
      "source": [
        "# 2nd ATTEMPT:\n",
        "history = autoencoder.fit(x_train, \n",
        "                          x_train, \n",
        "                          epochs=25, \n",
        "                          batch_size= 105, \n",
        "                          shuffle = True, \n",
        "                          validation_data=(x_test, x_test), \n",
        "                          callbacks=[early_stopping])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 202s 3ms/step - loss: 0.4463 - val_loss: 0.4407\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 201s 3ms/step - loss: 0.4524 - val_loss: 0.4378\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 201s 3ms/step - loss: 0.4689 - val_loss: 0.4715\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 199s 3ms/step - loss: 0.4742 - val_loss: 0.4568\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 199s 3ms/step - loss: 0.4819 - val_loss: 0.4877\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 200s 3ms/step - loss: 0.4898 - val_loss: 0.4848\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 200s 3ms/step - loss: 0.4912 - val_loss: 0.4844\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 199s 3ms/step - loss: 0.5069 - val_loss: 0.5118\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 200s 3ms/step - loss: 0.4986 - val_loss: 0.4775\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O51ZAJXcA0x",
        "colab_type": "text"
      },
      "source": [
        "When we reduced the batch size, the results got worse but are still roughly the same as the last run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjIgZIsOU1LZ",
        "colab_type": "text"
      },
      "source": [
        "***Visualize Examples of Input Images & Their Decoded Reconstruction***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMiV2YsuXK_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode & Decode the Test Images\n",
        "\n",
        "#encoded_imgs = encoder.predict(x_test)\n",
        "#decoded_imgs = decoded.predict(encoded_imgs)\n",
        "decoded_imgs = autoencoder.predict(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y98OyvWeM-jt",
        "colab_type": "code",
        "outputId": "af54b869-c644-48f2-b0c2-7bcdfddddd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "## Visualize an Example\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[-i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "\n",
        "    if decoded_imgs is not None:\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(decoded_imgs[-i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAD2CAYAAACgGUC/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3debQdVZn38Wc3DQoikJAQQhIgQACJ\nzGEyiEBABGWQVoFXMa20UeTFsVHQhQN2t0ArrfK6wLTKYLOiNKBGDSAJURRlSJB5CgECgUBAaBEb\nbaTr/SM3m99+uFU599wzVO37/ayVxXNu1T1n3/OcXVWn2M/eoSgKAwAAAAAAQH7+pt8NAAAAAAAA\nQHdw4wcAAAAAACBT3PgBAAAAAADIFDd+AAAAAAAAMsWNHwAAAAAAgExx4wcAAAAAACBTw7rxE0J4\nSwjhvhDCAyGEUzvVKPQWeWw+cpgH8th85DAP5LH5yGEeyGPzkcM8kMfmC0VRtPeLIaxlZveb2cFm\nttzMbjaz44qiuLtzzUO3kcfmI4d5II/NRw7zQB6bjxzmgTw2HznMA3nMw98O43f3NLMHiqJ40Mws\nhPB9MzvSzEo/ACGE9u4yYdiKogglm4aUR3LYV08XRTF2kJ9n0RcnT56cPP6f//mfGOsN6j//+c/J\nfuuuu27pc6699toxfvjhh4fZws4YqX1xnXXWifGrXvWqZJvm+i9/+UvP2jQMWfRFzcnf/u3LlwNV\nfep///d/Y/w3f/M3pdt8Hl/96lfH+E9/+lPpfr00UvtiZrLoi0rPWxMmTEi2+fPfaiGkH2U9Z2q/\n9PvqsffZZ58demM7hL6Yhez6Yqs23njjGK+11lrJtpUrV/a6OcPSxL6ox0yz9NpmzJgxMV6+fHmy\n30svvTTk11pvvfWSx//93/895OfogbK+OKwbPxPM7FF5vNzM9vI7hRBmmdmsYbwOumuNeSSHtbGs\n5OdZ9MUzzjgjefz444/HWL8cLlmyJNlv6tSpMfZfRMeOffm49773va8j7eyirPvipptuGuPtttsu\n2fbQQw/F+IEHHih9Dv3C0u5o1Q7Joi+OHz8+xtpXdtxxx2Q/vTjSL556M8csvQDyN1qnTJkS48WL\nF8f4/vvvH2KreyLrvpiZLPqi0mPlF7/4xWTbvffeG2M93/kvmy+++GKMn3/++WSb9ls99l522WVt\ntrir6IvNkV1frLrm0G1HHHFEjDfccMNkv6997WttPX8N1bYv6jHTzGzzzTeP8fvf//4Yn3LKKcl+\nzzzzzJBfa4cddkgeL1q0aMjP0QNlfXFYN35aUhTFbDObbda8O7hYhRzmoe55nD59evJ46dKlMR49\nenSMP/e5zyX77bLLLjF+zWtek2zTL5sNO8EOqu459D71qU/FWEf53HTTTcl+M2fOjLHe8DMzO++8\n8wZ97qr/w113dcnjfvvtF+N3vvOdMR41alSyn17IbrnlljF+29velux38cUXx1gvvMzSfJ1//vkx\nPvHEE4fY6nqoSw4xPHXM4zve8Y4YH3LIIcm2ww47LMb6f7n9/7n+wx/+EGN/40dH9+l5tqY3ftao\njjnE0NUlj61eK+r/rDzzzDNj7Ec0682Gf/3Xf23rtZqiEznUG9o6WnHGjBnJfm9605ti7CsG9H8o\n6f/gOumkk0r30xtEfpTW5ZdfHuNDDz002TZr1sv3ufS7ih85/atf/SrG+nnpteFM7vyYmU2SxxMH\nfoZmIY/NRw7zQB6bjxzmgTw2HznMA3lsPnKYB/KYgeHc+LnZzKaEECaHENYxs2PNbG5nmoUeIo/N\nRw7zQB6bjxzmgTw2HznMA3lsPnKYB/KYgbZLvYqi+GsI4f+a2dVmtpaZfbcoirs61jL0BHlsPnKY\nB/LYfOQwD+Sx+chhHshj85HDPJDHPAxrjp+iKOaZ2bwOtQV9Qh6br6k51JpdX6Ork67pyiY77bRT\nst8mm2wSYz+587hx42J84IEHxnjBggVttri7mpJHnUhU55bwudFJgo8//vjS57v66qtj/IUvfCHZ\n9ta3vjXGP/vZz2LsV3HQyUz7qSk5NEsnedU5QZ5++ulkvxdeeCHGOkeBn4/pJz/5SYx1Elozs3e9\n612Dvm5dNSmPGFxTc6hzSDzyyCPJNu2L/nyndLUuv+rMX//61xjrfD+6+o3ZK48D/dLUPOJlTcqh\n9gm9rjjggAOS/bbeeusY60qVGpuZTZw4McZ+/jxdSa/suqpOepFHvwrhahtssEHyWN9XP8Gyzmum\n1/s6n6R/Tr228cc+/Z6x++67J9v0cdXKiDoHqZ+j8stf/nLp73XacEq9AAAAAAAAUGPc+AEAAAAA\nAMhU15dzB4AyWurll0/UoZo63N0Pt/3zn/8cYx3ebpaWi2277bYxrmupV1OUDUk+/PDDk/2++tWv\nDvr7VWVaZ599drLt4x//eIy11CuHpU/77T3veU+Mp0+fHuN77rkn2e+hhx6K8fLly2O8/fbbJ/vp\ncqVPPvlksu22226L8ec+97k2Wwzkb+edd46xL/V67WtfG2M9Buox2Sw9L/rSiT/+8Y8x1vKDadOm\nJftdddVVQ2k2kIWyEsojjjgiebx06dKWnu+xx15e+Ootb3lLsm3OnDkx1hKzupZ69do222wT4x/+\n8IfJtkmTXl5gzB/jNt544xhrqeuXvvSlZL+vf/3rMdbvFpdddlmyn35XufTSS5NtH/rQh2LsS86U\nHmv1+41ZeamXLwnrxHUvI34AAAAAAAAyxY0fAAAAAACATHHjBwAAAAAAIFPM8QOgb8aPHx9jnXfA\n+8tf/hJjres1M3vuuedi7Ot8tbZXl2PE8Pi5lFbTOZXMzG699dZB9/NLr+ucP37pYV0aVee38J8X\nrcsvWw4UKa0zv+mmm0r30/fz5z//eYz9PASbbrppjB999NFkm85fULUMNTASvepVr4rx+uuvH2Nd\net0/1vke/FwQehzV+X78c+hyxpwjm0lz7+d6Uq3OD+KfQ8/3OueKmdkOO+wQ47lz57b0/HVXdn2j\nf6uZ2fe+972Wnk/Pme973/uSbTrHD/MWrqJL3ut8OjfffHOy33XXXRfjMWPGJNv0mlL7xy233JLs\nd8IJJ8T4yiuvjPEpp5yS7Pf5z38+xvfee2/1H1Bin332ifELL7yQbDvooINiPH/+/Bj7vujPB+3g\n6gsAAAAAACBT3PgBAAAAAADIFKVeAPpmiy22iLGW9JilQzW11MSX+GgJicZmaRnY5ptvPrzGjmB+\nuKmW+IwdOzbGWq7gaT59qVdV6Y+WLOhwWL+0p7aRUq/WXHzxxTHWvjJv3rxkv49//OMx1vIwPzT9\ngQceiLHvp2eeeWaMN9poozZbjFa1ugzsdtttlzzWUto99tgj2aZ9ceutty59Dn1t39cff/zxGK9c\nuTLGftlyHQrvP0u+7+dAyxv0PObPi+uss06M9Xjrj6HrrrtujLVU2u+r2/QYjd7Q85YvnZ06dWqM\njz322GTb6aefHmPt250oBalaSnz69OnJ43bLXurE952y6wfto2bp+a7K7bffHuPJkyeX7qclZq22\nKUe65L0uy+5L7bRsy78/egzV0lntN2ZmM2fOjPGhhx4aY18eO3v27Bi/8Y1vrP4DSixdujTG/py2\n2267xVhLvbpR/seIHwAAAAAAgExx4wcAAAAAACBTlHqhtvxQ9Vb30yF/us2vBuWHlqtOrBBU1v6q\noXutDs/PhQ5V90PalQ5Bf81rXlO6nx/SrkNnX/3qV7fTRFh1qdf+++8f4z/84Q+lz1HVn6uGll97\n7bUxPvDAA0v3y72vdMNjjz0W43HjxpXu9/DDD8d45513jvH999+f7LfhhhvG2H9mdIg1ZZfd50sF\ntI/pcfczn/lMst9WW20VY3/O1OfQcr3f/OY3yX5apjVjxoxk23rrrRdj/fz4Y7ce559++ulkW46l\nXhMnToyxHiu1BNMsff+0nEtX1DNLS378uVU/G1q+p8+H3qg6b+26664xfs973pNs23LLLWP8kY98\nJMZaem1mNnr06Bj7Uni9ttXPgS9D0efU8nwzs4suuqi0/U3hz1X6vmy//fYx9qWQN9xwQ0vPr8+n\npUtmaZnsfffd11KbcnfZZZfFWK/h//Ef/zHZT0sh/WpdulqhP4aW0VW9qvhySl29dtmyZTH2fXvv\nvfcu3bZ48eJBX6sbeWfEDwAAAAAAQKa48QMAAAAAAJApbvwAAAAAAABkijl+eqiqZrOqzlfr8X0d\n/DbbbBPjVpcWbKqy96jqvdt2221jfPTRRyfbFi5cGGNfq6u50Xr4ocwjovu2Ol+Rf379vRznMNHP\ns59fQP92zYGfi0TnL/iv//qv0teqmkcG1arqjPUY9M1vfrN0v6plZqu26XHt7W9/e0vPMdLmymqX\nzhOhy5X6eV9+8pOfxFjndPLzFWyyySYx9kt8//KXv4yxn2sCnVd1ztF5E/wSuToX2kMPPZRs0/zq\nMu1+SWc9Xj/xxBPJNp0nQ+er8cvn6jHnwgsvfOUfkTE9Xvn5eTSvv//970ufQ5eN9vM9af/T60uN\n0T2aw6pz6yGHHBJjP5+aLv+sn4NWrzW9xx9/PMb+e4bO3fbpT3+6reevM98/lH6H0ONmu3x+dE41\nneOn3TzmQM8tl19+eYz1/TFLv9P57w+aK53v58Ybb0z2O/fccwdtg865ZmZ2/fXXx9jPOdeqgw8+\nOMZjxoxJti1YsGDQ32E5dwAAAAAAALSMGz8AAAAAAACZYrx1BR1qV7Vk+IQJE5Jt++yzT4x1ebiq\n5aqr+GGX6u/+7u9ifNZZZ7X1/L3WavlS1VDHqjIqXYL2ta99bYzvuuuuZL+TTz45xjos2sxszpw5\nMe7EcnraRl/moI91iKNZdQlMDnTZX1121CxdUlSXGtUhyWbpssJVuRrJQ2fbocOf/edQP7NauuGX\nzdTy1lZL7fySqdondLn4XXbZJdlPl9T0ZbW596N2aVmPLreuy7ybpUtrv/71r4+xz8H3v//9GGsZ\nmVk6FLtqaD26T8+fvhRLS2m1DMEs7X967NaSFLO0D+tnzCztz3oc8cuRa+nX7373u0H+irzo+6Ln\nKn881Pdd37OvfOUryX7nnXdejLX/mpk99dRTg76WnmfRf3p8XblyZbJN+8eiRYtiPJTrHO1/Gvuy\nSz1/3nzzzS0/f1NUnY+0ZHnFihUdf219fv2+OJLPkVdddVWMv/SlL8VYv1ubpeWOP/3pT5NtWo6l\nZVt+SpSyZdTLfj4YPb5q+fsJJ5yQ7KfXVVpab5aW2eq1UtX0Fe0auZ8sAAAAAACAzHHjBwAAAAAA\nIFPc+AEAAAAAAMgUc/y0qGrukDe+8Y3J47322ivGm222WYy/8Y1vtPXauoSqr6X3c2o0Qavz+rQ6\nt47O6WOWLr+oNesPPvhgst+3v/3tGO+9997JtuOPPz7Gv/3tb2Ps50N4/vnnS9u1zjrrxHj8+PEx\n1nmHzNI5opYvX55s8/MS5UbfT7+ssM6JpfXOfknHadOmxdjP7aI5YJ6XoamaK+A973lPjP2Sz0rn\np2h1jp8qy5Yti3HVHD8s396aZ599Nsb/8R//EeODDjoo2e+II46I8Z133hnjUaNGle43b968ZJvO\nUTF27Ng2WwyvnbnL9Hj68MMPJ9t0bjV/fitbQtrPz6PHbl1K1yyde0GvX/Q6xyztw76NOdL5H3S+\nHz2HmaU50W06/5JZOreSPx7q8+t1lp/bBd1RNs/lm970pmQ/nevDz5W13nrrxVjnffLXQNrX/bwx\nmnuNdb4R344cz636/nnbb799jFu91vFzdVa9lp9HbbVOLB3fVPo993Wve12Mr7vuumQ/PVdVnYP0\nPdfvC2ZmJ554Yox1Pl0/35nm1H9f3HrrrWP85JNPDvpz334/x49+59T7BmeccYZ1GiN+AAAAAAAA\nMrXGGz8hhO+GEFaGEO6Un40OIVwTQlgy8N9RVc+B/iOPWdiSHDYffTEL9MUM0BezQF/MAH0xC/TF\nDNAX89ZKqdeFZvb/zOxi+dmpZragKIozQwinDjz+dOeb1186ZNKXiehwMR2KZpYO9ZoyZUqMf/jD\nHyb7PfPMMzHWoZRmaUmDLg/nh0370qAKF1of81i2nLn/e/T98iU9WpagdFicmdn6668fYy0l0qGx\nZukwwYULFybbtBxrjz32iLEfpqmP/dBMHRqow7P9cu4bbrhhjHWZ1UE8bWb/xzLqi/r59X1APzO6\nXOKSJUuS/fT3fGmCDv+sUbnAhdaAY2pVqaUuj3nFFVeU7tdOeV3V71x99dUx/uxnP1u6XyfKytYg\ni76opVpaOnfttdcm+51zzjkxnj9/foz9MVWXWz3llFOSbXoe02Nvn11oDeiLVcpKL6pKwLQ8esst\nt0y26XlXh8ubme24444x1vOYln2ZpSUljz/+eLJNf2/06NEx9udPvY5aw5K2WfRFvR7UY68v8dG+\no9eo11xzTbKfllb65dw1B/r8a7j+6LYLreF9sVVl51Y/lYPm2pf8lZUTVfV7/7r6nFqq5Pu9nu91\nagIzs9tvv10fNqYvlpXbeVrqdfbZZ5fuV1XepfS4ZpZOTaGqrr98jrtQfneh9bEvnn766TE+7LDD\nYqxl5mbpdz9fxqjHU32//LXHRz7ykRjr++inUdFrSp9rnUZEr6nuv//+ZD/9fvupT30q2XbwwQfH\n+JFHHrFuWuOIn6IorjOzZ9yPjzSziwbii8zsqA63Cx1GHrPwvJHDxqMvZoG+mAH6YhboixmgL2aB\nvpgB+mLe2p3ceVxRFCsG4ifMbFzZjiGEWWY2q83XQXe1lEdyWGv0xTzQF5uPvpgH+mLz0RfzQF9s\nPvpiHuiLmRj2ql5FURQhhNJxZkVRzDaz2WZmVfvVhQ4X05IDP1T2ne98Z4x1JnCzdOislgz54Xn6\nWn7b1KlTY/zoo4/G2Jc7+bKhdlXlsdUcVg0x1fdk5513jrFfRUKH4X3sYx9Ltn35y18e9Pduuumm\nZL/99tsvxuPGvXxs8qtp6eoiOszVLC3h0pn8fSmRtsOXqGh+deZ+nzN9b1pdyWwwTeyLK1asiLF/\nX3TYpW677bbbkv2OPvroGPvPoPbbbg+f7JRO9MUOtaN0m5bX3X333aX7tVNy5V9XVxjxx1q17777\nxvjXv/71kF+3k5rSF7VsUvuKL8FdsGBBjK+//voY++P3b37zmxj70s3dd989xlWfmTqpS1/sNF1l\n0udQ+5tfxVKHtGuJsi/50+OwXx2lrOTPn5+HUMZeqSl9Uc/9Wmrjz4t6raK/44+1WmbgpyNQev1R\nVk5fB03ui62W5hx1VDqIQq/9fUmm9ist+au6DvefJb1m1eujqs+BHsfNzK688srSfb1+9kVfKle1\napaWoOpxyZcTKT1/+lIgfS3fT/X5W10ZrN8rq3W7L/7TP/1TjPU49uEPfzjZ75JLLolxVRmj8vvp\n6s4zZsyIsT9vaQ79Coo33nhjjPW740UXXZTsp9db+jeapX3Or17Wae2u6vVkCGG8mdnAf1euYX/U\nE3lsPnKYB/LYfOQwD+Sx+chhHshj85HDPJDHTLR742eumc0ciGea2Y870xz0GHlsPnKYB/LYfOQw\nD+Sx+chhHshj85HDPJDHTLSynPscM/utmW0XQlgeQjjBzM40s4NDCEvM7KCBx6gx8piFyUYOG4++\nmAX6Ygboi1mgL2aAvpgF+mIG6It5W+MEMUVRHFeyaUbJz3umqm7W12LqNo21NtasfE6KD33oQ8lj\nrX33NfJai6v1034ZP31tX3eoNd5aW+jnXtB6fD8PkT5HL/JYVXeq7VR+Xhytc7zllluSbbp882WX\nXRZjP+eL1kVPnjw5xr7mc+utt46xn8tAl0I9/PDDY/yZz3wm2W/27Nkx9svPv+9974vxD3/4w9LX\n0vkRdP6DQTxUFMW0QX7e977YLp3Hoaovau2zXx5YjwP+mKA5r8ty7nU+ppbxS46W1U97nahFL6t1\n93N7feITn4hxD+b4yaIv6jLZutSon+PhoIMOirH2P98Xx44dG2NdJtUsnR/NLz3dL03si62q6nun\nnnpqjHW5YrN0uWY/d4/OfaHL5fq5Q9Zff/0Y+2sWvS7Refb8suU6D9EaZNEXlc5lVjXHT9WcZ7o0\n+7Rp6duj16x6LK96vm4bqX3xgx/8YIz99xa9bvbXR/q9QD8j/vNSNS+NXn/p8dn/jr7WpEmTSp/P\natwXq+b0+fu///vk8bvf/e5Bf+/EE09M9jvttNNirPOJbr755sl+t956a4x9H9PrG/2OeNJJJyX7\nzZkzp7T9ndbrvujnd3vve98bY50Xx3+H1nOLn1NQzy06745/rd///vcxfsMb3lDaRj1OVn2Wqixe\nvDjGb33rW5Nt2v+++c1vtvX8rWq31AsAAAAAAAA1x40fAAAAAACATHVmLfAu0/KNspItr2pZbB0y\nWbXc8HHHvTzabdNNN022aRmSXwp8o402irEOI9Oh0WZmY8aMibEffuaHda7mh2DqUGwdqm+WDi/s\nt+eee27Qn/syDv17li5dmmzTYeYzZ86MsS830PdOy6p0yT2zdLieHyaoS9VqPv0yfvvss0+Md9ll\nl2TbDjvsEOOzzjorxsuWLUv205KzVktocnHvvffG2JcDar/XkkA/3FP7uh/mrM+hr4Wh0c+vWfWS\nsZ1Wdpz3S1764dpYMz0+7rnnnjGeOnVqst/pp58eYy2D3WmnnZL9zjvvvBj788+8efNi7PspOkPf\nV19GfcABB8RYl1H358UDDzwwxn5J2wsuuCDGen7TsiIzs/e///0x1s+LWXoO1ef3JdArVqyIsS+d\n0KWnc6Tvkb++1GvWqutcfY/8NAC+rG61qiWk0R1a6uXL0bWsSktXzNLPhcb+M6HHAV+6qeUleu3p\njx1anumXlW8KLWE1Mzv00ENjfMQRRyTb9Pio37n8dzjNiX7Xu+eee5L9tF/p9z6z9Jh95513xvgf\n/uEfkv10mokzzjgj2faf//mfMS77vlxn+h3LzGz69OmDxlpOZ5ZOr7Hjjjsm2/QzrO+Jn5pF3yMt\naZ8/f36yX1V5l35/1+9zX/rSl5L97r777hiPGjUq2Xb77bfH2H/OOo0RPwAAAAAAAJnixg8AAAAA\nAECmGjHeumy4mi970se+hEufo6q8S1di2m677WKsK0WZpcP1fNmDlg099thjMfblXDok0w+p1qG4\nrQ7dO+SQQ5LHvS71qmqn5kbLqPzw7qoSgJtvvjnGuhrBvvvum+ynudKVQY4//vhkP33PfW622Wab\nGGsJ0sKFC5P9HnzwwRj72fp1qKGuduNLjnRYd9kQ7Fxp2ZsfZq4le/r58X2xauULHbKrpQNYM+1X\nfpj5Bz7wgZ61o+yY5/ubHk99yWS7qzDkTssmtWzLH4d1tUE9r/hzsJYN+RKfE044IcZaMoSh8dcb\nWuahn3M9z5ql5dFaRr333nsn+/3gBz+I8f77759sO+aYY2Ks5V3+vKXb/Dl+k002ibGeI/VaySw9\nJ4+0Euiq1c5U1bWsTkfgz4t6TNUc9HNVr5FEj4XaT7VcyKy6rK9sVWBfMq/HaD8tgl4D62v5Ui/9\nPPpVAKvKS+vk2muvTR7r31u14rKufLnFFlsk++lxSY95vl/q94mqa1T9LPjvhHo81FWvzMx+9rOf\nlf5eE/hr+gULFsRYy8e1FM4s/VzqdyyzNAd6LaJThpil589zzjknxhdffHGyn5YK+mPyzjvvHGO9\nVvKr4d5www0xfuc735ls0zZ+4QtfGDTuFEb8AAAAAAAAZIobPwAAAAAAAJnixg8AAAAAAECmajPH\nj58rQGk9sta3+5rXqqUt1WabbRbjo48+Otmm8/MsWbIkxuuvv36yn9bRak2fWVpnr233SykqXxOq\ntda6TZdVNEv/Zl32rm70b9CaSj8PgdY4+yVINW86R8Gzzz6b7Kd1tzp/ji5XbGa26aablr6WLtP+\ny1/+Msb+M7b77rvH2C9Zr3PWnHvuuTHWuRbM0mVX/VxDTVyacSj0PfLvnx4T9G/X+Z3M0hpzPxeE\nLleKodG++Ytf/CLZpjXrU6ZMiXHVUrKaTz8XgNa9+xp4PXZo7OvCdalMX4PNHD9rpscyf64qm+PH\n51vnL/vKV76SbNPlaf08NTmr+ltbnb9Q9/O/o59tfS0955ilcwjssssuMfZ9Ra9tdJ4YM7Pjjjsu\nxjoHol++WPumP7fq50eXjtc5/Dzdz8zsgQceKN03B7qc7+TJk0v388dK9dBDD8XYz7el50ztwy+8\n8MKQ2onW+O8Ip5xySozvuuuuGPul0vV6v2qeK+3D/pis3yX8Nv0c6PLSem1sZnb//feXvrb+bX6u\nnH775Cc/GWP/2db3Rb/3+cf6HcJfR/i5D1fz77POX+ZzrNeouqy5X3Zcr5X9PDWzZs2K8Zw5c2Jc\nt3y0Sj9T+nf784y+d/77gy71/uMf/zjGP//5z5P99L3U76baL83M3vjGN8b4iCOOSLbpUux67fTw\nww8n++l8Uf459Lyoc2gyxw8AAAAAAABaxo0fAAAAAACATPW81Gv10FRf2tRqmVZVuYsu5+aX3dMl\nCHWJbz90T4eL6bC7DTbYINlPh4T55RP1b9F26O+YpcO+/FLW+hw67NsPV9ShvrosoJnZ1KlTzSwt\ni+qmVkuRtJzpox/9aLJNh6z6oa06XE+XTvRLD+v7pXnX99ssHQroPy86PF2HwGqJi1n1cqq6bK2W\nPfglO3W/kVyS4vOjOdD+4T9n+rn3ZQt1Xl607n7zm9/EeO7cuck2XQJaP7P+86uP9fjn81LVj3TY\ntT6HH549bty4GDdxSdN+02HU/nx8wAEHxPif//mfY+yHo+uSpwcddFCyTT8LOfdLX9rVToluq9dD\nZmn51cEHHxxjf17caqutYqznVj+kXcs89NxkZvarX/0qxnoOfsMb3pDsp33Tlxvsu+++MV68eLGV\n0WOClqaNBP5cqKreW6Ul0XrNa5aeW7Vf+jLqplp9DTiUftSOVvv6BRdckDzW46ZeD/qSML1W1tIk\ns/SaSM93fuoD/V7kvz/ssMMOMda+7kuYtC/68sIxY8bEuA6lRXos0rIqf22o76d+1zNLl73X99m/\nt2Ul6v5zp8/hz316TaPfP1KgmmwAACAASURBVH17tVzTfx/V9/1tb3tbjL/zne9YE+k0A3p8evDB\nB5P9dEoOf67S74vKX7Non9Xvjlpua2Z25JFHxnj27NnJNv2Ord8rf/SjHyX76fdRf96dN29ejLVP\ndQMjfgAAAAAAADLFjR8AAAAAAIBMceMHAAAAAAAgUz2f46dsLgedn6FqvhWN/RwPuuylX45Wayx1\nCTi/bKrWFurz+7pMfX4/n4TWjmot/YoVK0pfy7dXa0l1KXmdb8YsXe7RL8G4ul542bJl1g1DWXJW\n6191qddvfOMbyX76OfA1zUrfB//e6fu1ZMmSGPv6Y52Pwi8FeP7558e4ahnqN73pTTH2yxf/y7/8\nS4y1xnvSpEnJflXz1+S4hHsZPyeFvtdVSyJX9Wf/GK3T2mp/3N52220H3c/Pd6afX82hn+9Mt/n6\neN2mufa030+cODHZ5pfVxCvpHD/z589PtumxUnPq53vQ463/LOy6664daWfd+WO2ztPh563z872t\n5o9bep45+uijk216/qt6LX2s10r+ekuXbtbrC7N03glto59P4c1vfnOMN99882SbLsWu53j/WdK5\nGPy1Te789YjSa2Cdh8174oknYuznkNRrW33fq+Zaa5LV55Cq83/V/D96zvHXHvp7Vddn3/rWt2Ks\nc3uYmd1www0x1vmXdNlvs3QuF/9a2m+13+ucPmbpfD163jZLr6N1/i5/XNL9hjI/Xz/osc3PmaS0\nD+h3MbN0fhftb/5v1W16baI/N0tz4j93ZXPM/O53vyt9Lb3WMTP7xCc+EeN///d/t6bT70h6famf\nUTOzL3/5yzH2faeMz41+79B4s802K32OWbNmJY/32muvGN94440x9scOnd/uqquuSrbNnDkzxjrH\nVDfwrQgAAAAAACBT3PgBAAAAAADIVM9LvVbzS73qsCo/LFWXadOhcFVL5vmlzXVonA4b9kOxdHi6\nllv5IaP6fH6Isg6P1nb84Q9/SPbzy8+V0Xb4v1mHK/qh3auHZHa6XGj1e9buUpk6tNWXbuiwPl/6\no7nSbT6Hmg/Nmx8Cq+ULfkioDk/XYZ9+ib9FixbF+N/+7d+Sbffee2+M99hjj0HbZJZ+lvwyrlWf\n99z490WHFPulLZUvG2p1G6rpkFg/RPyOO+4Y9Hf8sVtVlRToZ9tvqzomqKphupR6rZnmzg+Hnj59\neoyvv/76GPt+qcPs/ZLAurRuzrTMySztO76ER8vftOxp9OjRyX56fvLnAS2J0j7mj316PNXlZ6dM\nmZLsd+ihh8b4tttuS7bddNNNMda/xZeT6+dHy9TM0usgvd7y1wL6HH4J3tzpdYA/L+p71moZv7/2\n1OfI8bpiuNeoVdMWVNGSfv2O89vf/jbZT6/btY2+32sf0+tms1dOGbCani/N0n7ljz9a3qulgX4a\nDS398tv8FBb9duCBB8ZYl6v33wn1GOivW/RcpWVg/hj1wgsvxPjOO++M8bRp05L99NrEf570u4b2\n9e222y7ZT9uvr2uWnnf9ubuJypYz92XDW221VYy1fLKKPy/qObPV8k/vrLPOirF+r9xmm22S/fQz\nctxxxyXb9Lvl5z73uRj7a28txW4XI34AAAAAAAAyxY0fAAAAAACATPW01GuDDTawvffe28zMTjjh\nhGSblsX4oYM6PFGHZfkhjb7kSukwOS2J8mUFOou+Du3ywxt1SJgfOqalZLpK1dSpU5P99Peq2q6l\nY34FKx0C7VfgWLlypZm9chb+4Vh77bVjyZRfzaxqeLK2QfOmQzHN0tnM/ZBFzVXV+6XlBzo00LdX\nc+jfOy0V0WHRfrituvXWW5PHZcN5fTmXzt6vw23N0qG/vnQiN76P6bBaX8ao9LPlh2pWlQahmpZG\n+mOc9m/tp344bNmKdb7/Vm0rOyb7478Oia1azQOD01Ux/Dm47Ljsc6Wr1/hjma74lbPddtsteazn\nbH+e0TLurbfeOsa+5EP5soSyMljfP/RaQXOoq2yZpeVDev1iZjZjxowY6+olvuRIjw9+dU4dnq/n\n1oceeqj0Oeq2clC3VZVd6vnOnzPL+POifmZyXDl09d+kq12ZmZ100kkx9mU7el2msV/xScuA9ttv\nv2SbHv+0vMv3Ae3fem71JTzaV173utcl27T86vbbb4/x8uXLk/00977US3OvpWP+M6eflz333DPZ\npmU5vqSwH8rKYv25SvuOPzfpZ0NLVf1+ukKxHq8WL16c7KfvkV/tUvP6yCOPxNiXt+60004x9ueR\njTbaaNC2N1XZanz+OlT/bn++K+O/E+i5RY+7VSsh+v6sJdGr73GYmc2bNy/Zb+HChTF+17veVdqu\ns88+u/wP6ABG/AAAAAAAAGSKGz8AAAAAAACZWuONnxDCpBDCwhDC3SGEu0IIHx34+egQwjUhhCUD\n/x3V/eaiHUVRGDnMwtrksfnIYRboixkgh1mgL2aAHGaBvpgBcpi3VibA+KuZfbIoiltCCK81s8Uh\nhGvM7O/NbEFRFGeGEE41s1PN7NNVT/SnP/0pLgeqdXBmZjvuuGOMdenYVzRG6pv98nxVy25r7anO\nF+LnpND6UF1Oz8+to/NO+BrpnXfeOcZae+uXFNblHn3dZ1ndtZ+vR+dl8PW7q5cJH6iX7EgOX3rp\npfg6r3/965Nt+vq+BlLrkXUunKeeeirZT+tafZ2nPtbY12zqY30+/5nQWlg//49+LrTuWmtKzdI8\n6bLsZmmu9LV9/bTW//o5j7Tmd0BH8lhHvn+0uiyl1m43ZL6CRuRQ339fN679RY9dvi9qXbTmxs85\nUda3zdLjtdZd++fQ+u8eLVHciDy2qmo+LJ1fQJcs9vMmbLHFFjHW85tZ68ut9lhHcjhq1Kj49/rr\nFz3H6ftjlp4zy5ZlN0vPp/6cqdcs2nf8fAj6HDr3ib+m0Ofw8ybo+e+oo46KsZ/rRPfz12llczH4\nZeX9OVkdfPDBMb7mmmvMMuuLOj+WvzbUxxMnTmzp+fznSY+pfk6YPup4Dr/3ve8lj3XOR51X1Cyd\nQ1HPVb5//PSnP43xRRddlGw77bTTYqxLOftjq57HtD/4eUB1/pFLL7002aZLQ+uclLqcuefnA9PP\ngbbD9z29Bvb9d5D5t/raF3/xi1/E+L3vfW+M/Zw5Oiegnz/pvvvui7Euea/zO5mlnyfNadX3Hz9/\nnh7PdZ43/1nQ993PBeXnDe2AvuZQ30vNW9ky72bVc6Dq9zn/HUE/v7rN3xso+17p6fnz2muvTbZ9\n9atfjfGZZ56ZbNPX3mWXXWKsnz+zV3622rHGET9FUawoiuKWgfiPZnaPmU0wsyPNbPVR7yIzO2rw\nZ0C/hRCMHGbhRfLYfOQwC/TFDJDDLNAXM0AOs0BfzAA5zNuQlrwJIWxpZrua2Y1mNq4oitW3Lp8w\ns3ElvzPLzGYNxO22Ex1CDvMw3Dyi/8hhHshj8w03h35EMPqDvth85DAP5LH5yGGeWr7xE0JY38wu\nN7OPFUXxnBs6VYQQBq2xKIpitpnNHniOYvWQtDPOOKP0tXzJzF577RVjHZ73hje8IdlPh+Hp0HSz\n8iWH/bAvLRHQ8pw77rgj2W9geLGZmV155ZXJtqphYGru3Lkx1iGDZumwNR0q7YdN6zBUPwRs9dKD\nq3/eqRyuLvvwQ2UnTJgQY7+MppbyaTv9e1U1zFy3aZ78c+g2Hcrql8jV99wPiy9bItcPa9XX8p8l\nfQ6N/bBrfU6/pO1gw7A7lcfB9uknn28tp6xazldz7N/bVpd47LUm5FBLSPxnW/uivv+e9nUtUfD9\nTf9+n2t9Dt3mS8J0iVO/FGe3NCGPrdLynA996EPJtsMPPzzGs2aVX9PpMra6FLHZK0uU6qITOXz1\nq19d3HLLLWZm9uY3vznZT4fv+8922bLt/jim5w9fLqbnIC0B8CVCWhak2/x+eu7250Ed7q5/i19W\nXEsbfFmCL51ZzZdnan/2xxjfZrO8+uLSpUtj7I9zmoNWj3M+B5rXsnz0QydyOHr06OKQQw4xs3S6\nBrO0hE7Pb2bpzVudQsFf++t3i0984hPJNv0Ootcefplz/T4yfvz4GPvlwq+//voYa+mYmdknP/nJ\nGOvfdeONNyb7rX4vzF5ZEqTfJ/Rz4D9X+rdUlYau1s++OGfOnBh//OMfL223lrP560QtOy2b9sEs\nPU6XfT8xS0vx/Pul5119LV+6pMdb/z8a9PrMn3fb1csc7rbbbsljPYfqeeBb3/pWsp/mt6o0WN8f\n/9nWfGg+/WdCc+oHQJRNVeBLAzVv3//+95Ntml89Pm+//fbJfrp0fLtaWtUrhLC2rfoAXFIUxRUD\nP34yhDB+YPt4M1s57Naga8hhHshj85HDPJDH5iOHeSCPzUcO80Aem48c5q2VVb2CmX3HzO4piuIc\n2TTXzGYOxDPN7Medbx46YeBuJznMA3lsPnKYB/LYfOQwD+Sx+chhHshj85HDjLVS6jXdzI43sztC\nCKuXY/qMmZ1pZpeGEE4ws2Vm9q7uNBEdQg6bb30jjzkgh81HX8wDOWw++mIeyGHz0RfzQA4ztsYb\nP0VR/NrMymb0ndHZ5qzilw5esGDBoPF5553XjZfvmSOOOKJnr1UURcdz6OuF9bGvgdSlJ0eNGhVj\nX2c9WO3+YLQWs2qOkaolivVz5mt3tSa0bLk/r2oeGp2nRGtWzcyeffbZGK+h3v75buSxLqqW+K6i\n71nVEsZ10ZQc6lxrft417QdVy6hrP9U8+eOD7lc1b4XWSOs8Imbp3CR6jOmS7PqiHr/f9ra3JduW\nLVsW46q5DObPnx9jnYPCzOzxxx/vSDs7qVM5/Mtf/hLnZfnABz6QbNt7771j/O53vzvZNm7cy/Nj\nbrLJJjHWeR/M0v7ij4vaFzUf/lio51btb/7cp/OR/OxnP0u2/frXv47xZZddFuPV8xutNmnSpBj7\nuZ30nFw1R54/5ig3p1B2fVGPbf66Qt+/qiWMlc4BY5Z+7vxnrV86lcNnn302zp8xffr0ZJvOC+r7\nh84RoucSnVfU83Ot6NxM+nx+Lq/nnnsuxjovmh4DzMw+/OEPx9jPqTlz5swY+3lG1aOPPhpjPx+m\nfrb0vFt1DvbP4fbte1/cb7/9YqzLsutn3iw9zumcS2bp8Va/X/i5S8vmPmp1zlCz9HOi76U/zuvz\n+/OuXuf6OWHa0esc+vPHZz/72Rjre+yv5zVvVXP8qFbnNPP7aW6q5qH0uVF6vNC5/8zMLr/88pba\n1QmtfbMCAAAAAABA43DjBwAAAAAAIFMtL+cODIUftq3D5nTod12X+EXv+eHFVUt8Kx0K6ofH6rKs\nGBrtm/791yVotSzBD2kuG+Lsh4vr8Fi/lLXmVH+vqkThmWeeKd2Gwekx2g871lIvHa7sy7I//elP\nx/iGG25ItvmyodysPl75c5++D/49URtuuGGMJ0+enGx7/etfH2NfeqIlDJobP1RdS4qvu+66GPvl\nn1esWFHaxjJf//rXk8dabuCXn9Xh+bqctMZmaV/3w/i15CxHDz/8cIz9sVLLSHxJSZmVK9MFeCZM\nmBBjX7Kfk5NPPjl5rOcWX5J57LHHxljfH38O08+pf++0xHiLLbaIsZ/CQK9tdHn4u+66K9nvqKOO\ninHVsaPKxIkTY7zpppsm2/yS1WU/1/O/n55BH2tZWb/sueeeMdaSOl9Gp9ccVX9v1X7a/7QE01/L\n6vNVTWGgn8+qsnl/PaZ/pz8nN9FXvvKVQX/ul0evKoEuU/XdVMv6/BQiVSVcZdOB+OOz5tCXF/YS\nI34AAAAAAAAyxY0fAAAAAACATFHqBaAW/GpnOjzarzxTxq8WVcdVvZril7/8ZYz90GUdPr7BBhvE\n2JdraN50mKsfAqvDdKtWsxg7dmyM/UopOhT32muvNQyNrnJy9913J9s0J2PGjImxH1b+ta99Lcb+\ns6DlSjmW6lSt+NgKff9vvfXWZJt/XDff/va3+92ErOi50J8X9bhXtfKZeuSRR5LHu+yyS4y1BDB3\nWpJx/vnnJ9v849X0vTIzmzp1aox32223ZJuu+qTnuAcffDDZ74477oixrlTsj5lV9Fqn6tjzjne8\nI8a+VEkfa+yvt7SMyR/z63Zs0hXstDTIXxtqCZ9f/bdqNWCl73tViU/VSpi+Xav5knf97Fa1b8mS\nJRUtbgYts9LPpS/XK1t9uYp///W1NE/+2FpV6qXfVbQdvsTzySefjHFVia3mt9VVyIaCET8AAAAA\nAACZ4sYPAAAAAABAprjxAwAAAAAAkCnm+AFQC752fN11142x1sZ6Wiur84+YvXJuA7RO66evuuqq\nZJsuhas1yFV10Vo/7eva9Tl8TbPWuuvv6TLWZmYXX3xxjFut98bLnnrqqRj75bNnzJgRY/9ZKHsO\nnWvBzGyPPfaIcY5z/ADd4I9lekxdb731WnoOP5+EHov9cvFIVc23dckll/S6OVGrc4pdfvnlXW5J\nveicWDq30pQpU5L99P3z1xy6Ta8//Htetky7nxNR+2zVXDFV10j62M/xo3MynXHGGaXP3xR+LqrV\nRo0alTwum5+nymabbZY81lzp+6hz7plV9zdth34m/DXqTjvtFOO3v/3tyba5c+dWNbujGPEDAAAA\nAACQKW78AAAAAAAAZIpSLwC18KMf/Sh5/O53vzvGl156aenv3XLLLTF+73vfm2y74IILOtS6kW3W\nrFnJY13Cff/9949x1TBmLQPz5Qs6jNYPY3766adjrEuwXnHFFcl+M2fOLH1trJm+twcddFCy7cor\nr4zx73//+9Ln0PLMjTbaKNl27733DreJwIinSxr7coQyr3nNa5LHG2+8cYy7sVww0C/nn3/+oD8/\n5phjksdawqWlOmbp9YkuCe+XWNdrFS1P8mVH+vwPP/xw6XNULeOtJZm+xPOuu+6ynGhZm14b+hKw\nO++8M8aTJ09Otn3wgx+M8cqVK2Psv2dMmzYtxttuu22M3/rWtyb73XHHHTH2Zey77rrrIH/FK69z\nb7/99hifeOKJg/7OYL/XaYz4AQAAAAAAyBQ3fgAAAAAAADLFjR8AAAAAAIBMMccPgFpYtGhR8ljr\nlm+44YbS3/vVr34V45133jnZpst5onOOPfbYGOucE4cffniy3+jRoweNfQ28zg3k563QOWXmzZsX\n48cee2yozUaFP/7xjzHWnJqZrb322i09xz333BNjv1yp1rcDaM1PfvKT5PEDDzxQuq3M/Pnzk8c6\nx89NN900jNYBzaBz9ZiZjR07NsZbbLFFsk3PY7o8fDdoO3RuF798+LPPPhtjnUvPLF2GPAdlS6cv\nXLgwebzjjjvG2M8p+PnPfz7Ger15+umnJ/vpe/nFL34xxk899VSy34oVK0rb+41vfCPGjzzySIyv\nv/760t/ROZu8qqXjO4ERPwAAAAAAAJnixg8AAAAAAECmQreHFCUvFsJTZrbMzMaY2dNr2L3b6tAG\ns960Y4uiKMauebc1q1kOzUZWOzqdxz/ZyHnvWtHEHNIXX6mJeaQvppqYQ/riKzUxj/TFVBNzSF98\npSbmkb6YamIO6Yv9aUNpHnt64ye+aAiLiqKY1vMXrlkb6tSOoapLu2lH++rSZtoxPHVpN+1oX13a\nTDuGpy7tph3tq0ubacfw1KXdtKN9dWkz7RieurS7Du2oQxso9QIAAAAAAMgUN34AAAAAAAAy1a8b\nP7P79LqqDm0wq087hqou7aYd7atLm2nH8NSl3bSjfXVpM+0Ynrq0m3a0ry5tph3DU5d204721aXN\ntGN46tLuOrSj723oyxw/AAAAAAAA6D5KvQAAAAAAADLFjR8AAAAAAIBM9fTGTwjhLSGE+0IID4QQ\nTu3h6343hLAyhHCn/Gx0COGaEMKSgf+O6kE7JoUQFoYQ7g4h3BVC+Gi/2jIcIzmP5HDYr0sOO6Rf\nORx4bfLYIfRFcjjM1yaPHUJfJIfDfG3y2CH0RXI4zNcmj2WKoujJPzNby8yWmtlWZraOmd1mZjv0\n6LX3M7PdzOxO+dnZZnbqQHyqmZ3Vg3aMN7PdBuLXmtn9ZrZDP9pCHskhOSSH5HHk5pEcNj+H5DGP\nPJLD5ueQPOaRR3LY/BySxzW0q4dJ2MfMrpbHp5nZaT18/S3dB+A+Mxsvybmvl2/8wOv+2MwOrkNb\nyCM5JIfkkDyOrDySw+bnkDzmkUdy2Pwcksc88kgOm59D8lj+r5elXhPM7FF5vHzgZ/0yriiKFQPx\nE2Y2rpcvHkLY0sx2NbMb+92WISKPA8hhx5DDoatbDs3IYzvqlkdyOHR1y6EZeWxH3fJIDoeubjk0\nI4/tqFseyeHQ1S2HZuTRzJjc2czMilW33YpevV4IYX0zu9zMPlYUxXP9bEtOevnekcPuIId5II/N\nRw7zQB6bjxzmgTw2HznMw0jOYy9v/DxmZpPk8cSBn/XLkyGE8WZmA/9d2YsXDSGsbas+AJcURXFF\nP9vSphGfR3LYceRw6OqWQzPy2I665ZEcDl3dcmhGHttRtzySw6GrWw7NyGM76pZHcjh0dcuhGXk0\ns97e+LnZzKaEECaHENYxs2PNbG4PX9+ba2YzB+KZtqr2rqtCCMHMvmNm9xRFcU4/2zIMIzqP5LAr\nyOHQ1S2HZuSxHXXLIzkcurrl0Iw8tqNueSSHQ1e3HJqRx3bULY/kcOjqlkMz8rhKLycUMrPDbNWs\n1kvN7LM9fN05ZrbCzF60VXWGJ5jZxma2wMyWmNl8Mxvdg3bsa6uGdN1uZrcO/DusH20hj+SQHJJD\n8tj/f/RFckge6/GPvkgOyWM9/tEXySF57M6/MNA4AAAAAAAAZIbJnQEAAAAAADLFjR8AAAAAAIBM\nceMHAAAAAAAgU9z4AQAAAAAAyBQ3fgAAAAAAADLFjR8AAAAAAIBMDevGTwjhLSGE+0IID4QQTu1U\no9Bb5LH5yGEeyGPzkcM8kMfmI4d5II/NRw7zQB6bLxRF0d4vhrCWmd1vZgeb2XIzu9nMjiuK4u6K\n32nvxTBsRVGEwX4+1DySw756uiiKsf6HTeuLu+++e79euiWLFy/u6vPn3Bc32WSTfjfBzMxWrlzZ\n7ZegL/YAfbFeOv156VB+6Ys9QF+sF/pi99AXe9sX6/5+91o3+6KZ2d8O40n3NLMHiqJ40MwshPB9\nMzvSzEo7MmqJPDbHspKfNyqHixYt6ncTKoUw6DmvFxqVx8Ecc8wx/W6CmZmde+653X4J+mIP0Bfr\npdOflw7ll77YA/TFeqEvdg99sVRX8lj397vXutwXh1XqNcHMHpXHywd+lgghzAohLAohkNl6WmMe\nyWHt0RfzQF9sPvpiHuiLzUdfzAN9sfnoi3mgL2ZgOCN+WlIUxWwzm202coZg5oYc5oE8Nh85zAN5\nbD5ymAfy2HzkMA/ksfnIYf0NZ8TPY2Y2SR5PHPgZmoU8Nh85zAN5bD5ymAfy2HzkMA/ksfnIYR7I\nYwaGc+PnZjObEkKYHEJYx8yONbO5nWkWeog8Nh85zAN5bD5ymAfy2HzkMA/ksfnIYR7IYwbaLvUq\niuKvIYT/a2ZXm9laZvbdoiju6ljL0BPksfnIYR7IY/ORwzyQx+Yjh3kgj81HDvNAHvPQ9nLubb0Y\n9X59U7Y831CRw75aXBTFtE48UT/z2MtjTju6vWJCzn3x5JNP7ncTzKwnq3rRF3uAvlgvnf68dCi/\n9MUeoC/WC32xe+iLve2LdX+/e63bfXE4pV4AAAAAAACoMW78AAAAAAAAZKrry7kDAPJSl5IurBnD\nqOHV5TPRiXZ0u+wB6Jde9lP6YnNU5YocNF+388uIHwAAAAAAgExx4wcAAAAAACBT3PgBAAAAAADI\nFDd+AAAAAAAAMsWNHwAAAAAAgExx4wcAAAAAACBTLOfeBXVb6vgHP/hBv5vQOO0sbckyikA9VB2D\nzz333B62BOiPuizZDqAc/bQ/eN8xUjHiBwAAAAAAIFPc+AEAAAAAAMgUN34AAAAAAAAyxY0fAAAA\nAACATHHjBwAAAAAAIFPc+AEAAAAAAMgUy7lXqNuy7Bi6Xi7Z2O3XYrl4AACaiSWkRybyjl6p+qzx\nHQJmjPgBAAAAAADIFjd+AAAAAAAAMsWNHwAAAAAAgExx4wcAAAAAACBT3PgBAAAAAADIFDd+AAAA\nAAAAMjXil3NnyfbmY6lMAAAAAAAGx4gfAAAAAACATK3xxk8I4bshhJUhhDvlZ6NDCNeEEJYM/HdU\nd5uJ4SKPWdiSHDYffTEL9MUM0BezQF/MAH0xC/TFDNAX89bKiJ8Lzewt7menmtmCoiimmNmCgceo\ntwuNPDbd00YOc3Chkcemoy/m4UIjj01HX8zDhUYem46+mIcLjTxma403foqiuM7MnnE/PtLMLhqI\nLzKzozrcLnQYeczC80YOG4++mAX6Ygboi1mgL2aAvpgF+mIG6It5a3dy53FFUawYiJ8ws3FlO4YQ\nZpnZrDZfB93VUh7JYa3RF/NAX2w++mIe6IvNR1/MA32x+eiLeaAvZmLYq3oVRVGEEEqXVSqKYraZ\nzTYzq9oP/VWVx7rkkNW7qtWpL5Kr9tWlL7LiYfvq1BfRvrr0xSoca6vRF/NAX2y+XvdF8tEdrfbF\nadOmFYsWLepp27Bm7a7q9WQIYbyZ2cB/V3auSegh8th85DAP5LH5yGEeyGPzkcM8kMfmI4d5II+Z\naPfGz1wzmzkQzzSzH3emOegx8th85DAP5LH5yGEeyGPzkcM8kMfmI4d5II+ZaGU59zlm9lsz2y6E\nsDyEcIKZnWlmB4cQlpjZQQOPUWPkMQuTjRw2Hn0xC/TFDNAXs0BfzAB9MQv0xQzQF/O2xjl+iqI4\nrmTTjA63BV1EHrPwUFEU0wb5OTlsEPpiFuiLGaAvZoG+mAH6YhboixmgL+at3VIvAAAAAAAA1Bw3\nfgAAAAAAADI17OXce40lhpuPJRYBACMN5z6g/uinzUGugKFhxA8AAAAAAECmuPEDAAAAAACQKW78\nAAAAAAAAZIobPwAAKWhRiQAACQpJREFUAAAAAJnixg8AAAAAAECmuPEDAAAAAACQqZ4u577JJpvY\nMccc08uXRIftvvvutmjRon43AwCAWuC8CNQDfREAyjHiBwAAAAAAIFPc+AEAAAAAAMgUN34AAAAA\nAAAyxY0fAAAAAACATHHjBwAAAAAAIFPc+AEAAAAAAMhUT5dzBzAyhBBivNVWWyXbli5d2uvmoMTJ\nJ5/c7yYAAABEu+++uy1atKjfzQCyw4gfAAAAAACATHHjBwAAAAAAIFOUegHoqgcffLDfTQAAAACA\nEYsRPwAAAAAAAJnixg8AAAAAAECmKPUC0HFrrbVWjF966aU+tgSs3AUAAACMbIz4AQAAAAAAyNQa\nb/yEECaFEBaGEO4OIdwVQvjowM9HhxCuCSEsGfjvqO43F+146aWXjBxmYW3y2HzkMAv0xQyQwyzQ\nFzNADrNAX8wAOcxbKyN+/mpmnyyKYgcz29vMTgoh7GBmp5rZgqIoppjZgoHHqC9ymAfy2HzkMA/k\nsfnIYR7IY/ORwzyQx+Yjhxlb442foihWFEVxy0D8RzO7x8wmmNmRZnbRwG4XmdlR3WokhmettdYy\ncpiFF5uSx3XXXTf+mzBhQvJvpGtKDlGpMX0R5chhFuiLGSCHWaAvZoAc5m1Ic/yEELY0s13N7EYz\nG1cUxYqBTU+Y2biS35kVQlgUQlj0wgsvDKOp6ITh5vCpp57qSTtRbbh57EkjUYkc5oE8Nh/nxTzQ\nF5uPvpgH8th85DBPLd/4CSGsb2aXm9nHiqJ4TrcVRVGYWTHY7xVFMbsoimlFUUxbd911h9VYDE8n\ncjh27NgetBRVOpHHHjQTFchhHshj83FezAN9sfnoi3kgj81HDvPV0nLuIYS1bdUH4JKiKK4Y+PGT\nIYTxRVGsCCGMN7OV3Wokhq9TOVy8eLGFENb4equOC2hFK++n7NuIvvj8888PGqM5OUQ18th85DAP\n5LH5yGEeyGPzkcO8tbKqVzCz75jZPUVRnCOb5prZzIF4ppn9uPPNQycM3IQhh3kgj81HDvNAHpuP\nHOaBPDYfOcwDeWw+cpixVkb8TDez483sjhDCrQM/+4yZnWlml4YQTjCzZWb2ru40EcP14osvmpHD\nHKxv5DEH5LD56It5IIfNR1/MAzlsPvpiHshhxtZ446coil+bWVktyozONgfdsM4661hRFOSw+Z4n\nj81HDrNAX8wAOcwCfTED5DAL9MUMkMO8DWlVLwAAAAAAADQHN34AAAAAAAAyxY0fAAAAAACATLW0\nnHunrFy50s4999wh/54uDd7q0td+OfGhLJldZ035u+raLmCk8cdcPYZ85CMf6XVzAAAAAPQYI34A\nAAAAAAAyxY0fAAAAAACATDXixk8IIf5r53dyKjvK9e8C0BscPwAAAICRpRE3fgAAAAAAADB03PgB\nAAAAAADIFDd+AAAAAAAAMtXT5dwBjAy6ZDgA5Gzx4sUtzZnFcbF1zEGGdtAXO68ffZE8Nh85rCdG\n/AAAAAAAAGSKGz8AAAAAAACZ4sYPAAAAAABAprjxAwAAAAAAkClu/AAAAAAAAGSKGz8AAAAAAACZ\nYjl3AMjYySef3O8mAAAAAOgjRvwAAAAAAABkihs/AAAAAAAAmQpFUfTuxUJ4ysyWmdkYM3u6Zy88\nuDq0waw37diiKIqxnXiimuXQbGS1o9N5/JONnPeuFU3MIX3xlZqYR/piqok5pC++UhPzSF9MNTGH\n9MVXamIe6YupJuaQvtifNpTmsac3fuKLhrCoKIppPX/hmrWhTu0Yqrq0m3a0ry5tph3DU5d20472\n1aXNtGN46tJu2tG+urSZdgxPXdpNO9pXlzbTjuGpS7vr0I46tIFSLwAAAAAAgExx4wcAAAAAACBT\n/brxM7tPr6vq0Aaz+rRjqOrSbtrRvrq0mXYMT13aTTvaV5c2047hqUu7aUf76tJm2jE8dWk37Whf\nXdpMO4anLu2uQzv63oa+zPEDAAAAAACA7qPUCwAAAAAAIFPc+AEAAAAAAMhUT2/8hBDeEkK4L4Tw\nQAjh1B6+7ndDCCtDCHfKz0aHEK4JISwZ+O+oHrRjUghhYQjh7hDCXSGEj/arLcMxkvNIDof9uuSw\nQ/qVw4HXJo8dQl8kh8N8bfLYIfRFcjjM1yaPHUJfJIfDfG3yWKYoip78M7O1zGypmW1lZuuY2W1m\ntkOPXns/M9vNzO6Un51tZqcOxKea2Vk9aMd4M9ttIH6tmd1vZjv0oy3kkRySQ3JIHkduHslh83NI\nHvPIIzlsfg7JYx55JIfNzyF5XEO7epiEfczsanl8mpmd1sPX39J9AO4zs/GSnPt6+cYPvO6Pzezg\nOrSFPJJDckgOyePIyiM5bH4OyWMeeSSHzc8hecwjj+Sw+Tkkj+X/elnqNcHMHpXHywd+1i/jiqJY\nMRA/YWbjevniIYQtzWxXM7ux320ZIvI4gBx2DDkcurrl0Iw8tqNueSSHQ1e3HJqRx3bULY/kcOjq\nlkMz8tiOuuWRHA5d3XJoRh7NjMmdzcysWHXbrejV64UQ1jezy83sY0VRPNfPtuSkl+8dOewOcpgH\n8th85DAP5LH5yGEeyGPzkcM8jOQ89vLGz2NmNkkeTxz4Wb88GUIYb2Y28N+VvXjREMLatuoDcElR\nFFf0sy1tGvF5JIcdRw6Hrm45NCOP7ahbHsnh0NUth2bksR11yyM5HLq65dCMPLajbnkkh0NXtxya\nkUcz6+2Nn5vNbEoIYXIIYR0zO9bM5vbw9b25ZjZzIJ5pq2rvuiqEEMzsO2Z2T1EU5/SzLcMwovNI\nDruCHA5d3XJoRh7bUbc8ksOhq1sOzchjO+qWR3I4dHXLoRl5bEfd8kgOh65uOTQjj6v0ckIhMzvM\nVs1qvdTMPtvD151jZivM7EVbVWd4gpltbGYLzGyJmc03s9E9aMe+tmpI1+1mduvAv8P60RbySA7J\nITkkj/3/R18kh+SxHv/oi+SQPNbjH32RHJLH7vwLA40DAAAAAABAZpjcGQAAAAAAIFPc+AEAAAAA\nAMgUN34AAAAAAAAyxY0fAAAAAACATHHjBwAAAAAAIFPc+AEAAAAAAMgUN34AAAAAAAAy9f8B8Uk8\nOF4idxEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaPb_fyU6F5r",
        "colab_type": "text"
      },
      "source": [
        "The decoded images do not look like the input - a sign that information was lost in the training, which corresponds to what we expected based on the loss above. We can see that the model caputures the rough shape and shading, ut not much detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt6qP05VHqKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map input to encoded representation\n",
        "encoder = Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT-HFa4Sk16N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "3d6b6601-47cd-44fa-98d3-0a90a30ffaeb"
      },
      "source": [
        "# Evaluate\n",
        "def plot_train_history_loss(history):\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    #plt.title('Convolutional Autoencoder Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "plot_train_history_loss(history)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAFQCAoBKQABQCQgAKgEBQHUAgbIpM/8ILaEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK-uwduTe910",
        "colab_type": "text"
      },
      "source": [
        "The plot shows that the loss actually increased with each epoch, rather than decreasing, and then might have found a local minima at the end, where it slightly decreased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foOcdla1NBYi",
        "colab_type": "text"
      },
      "source": [
        "###**2. Image Classification**\n",
        "Weâ€™ll continue to use the Fashion MNIST dataset and build a deep convolutional network for classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceYJQ87pkWC4",
        "colab_type": "text"
      },
      "source": [
        "REFERENCE: https://towardsdatascience.com/mnist-cnn-python-c61a5bce7a19\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnd420XJOX_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT & PREP THE DATA\n",
        "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape images as per the tensor format required by tensorflow\n",
        "train_X = train_X.reshape(-1, 28, 28, 1)\n",
        "test_X = test_X.reshape(-1, 28, 28, 1)\n",
        "\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "\n",
        "train_X = train_X / 255\n",
        "test_X = test_X / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQUZlUdMzrae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One Hot Encoding\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7638mwBNBjD",
        "colab_type": "text"
      },
      "source": [
        "**2.1 Deep CNN**\n",
        "\n",
        "Build a deep CNN to classify the images. Provide a brief description of the architectural choices youâ€™ve made: kernel sizes, strides, padding, network depth. Train your network end-to-end. Report on your modelâ€™s performance on training set and test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d0Lk5LcNB_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the Deep CNN Model \n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(28, 28, 1)))   # 64 neurons (feature maps) and a 3x3 feature detector\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))     # use max pooling with a 2x2 matrix\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))     # use max pooling with a 2x2 matrix\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))                         # implements the operation output = activation(dot(input, weight) + bias)\n",
        "\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh8eXbWoiAxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpQVXWneuumo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "e756df31-1d8e-4427-b00d-f49406f5ef1e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                102464    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 140,682\n",
            "Trainable params: 140,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxebZXHzNLC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "35bf3537-9a9c-4fd0-a368-51d39790ee76"
      },
      "source": [
        "# Incorporate early stopping \n",
        "#from keras.callbacks import EarlyStopping  \n",
        "\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')\n",
        "\n",
        "# Train model\n",
        "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=15)\n",
        "                   #,\n",
        "                   #validation_data=(test_X, test_Y),\n",
        "                   #callbacks= [eary_stopping])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 131s 2ms/step - loss: 0.1433 - acc: 0.9470\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 129s 2ms/step - loss: 0.1345 - acc: 0.9506\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 128s 2ms/step - loss: 0.1256 - acc: 0.9533\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 128s 2ms/step - loss: 0.1200 - acc: 0.9552\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 129s 2ms/step - loss: 0.1130 - acc: 0.9583\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.1092 - acc: 0.9594\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.1035 - acc: 0.9614\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0981 - acc: 0.9628\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0959 - acc: 0.9644\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0897 - acc: 0.9666\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0843 - acc: 0.9688\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 126s 2ms/step - loss: 0.0819 - acc: 0.9699\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0782 - acc: 0.9709\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0770 - acc: 0.9717\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0703 - acc: 0.9737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1feb9df240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9EeXoRYy4J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch4YQmroy5gS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f236dd68-6ead-47ca-b8e3-396cc54ba082"
      },
      "source": [
        "# SAVE MODEL\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddRz0UNC0dz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ba8e8ed8-ec7c-4587-93af-068ca2b7d4bd"
      },
      "source": [
        "# Evaluate Model & Validate results with test data\n",
        "test_loss, test_acc = model.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
        "print('Test loss', test_loss*100, \"%\")\n",
        "print('Test accuracy', test_acc*100, \"%\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss 42.944968256950375 %\n",
            "Test accuracy 89.94 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlkX4JWt0NR4",
        "colab_type": "text"
      },
      "source": [
        "Based on the fact that the accuracy is so much lower for the test data than for the training data, there is evidence to suggest that we may have overfit the model to our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivH6UhwCjwc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13bf1ab5-981e-4245-ca2e-bb75796e3a20"
      },
      "source": [
        "predictions = model.predict(test_X)\n",
        "print(np.argmax(np.round(predictions[0])))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Mo40tA00bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the label names\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCqFtei9kSh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b3173f63-68ba-4767-fc81-bb7d1b9f0f55"
      },
      "source": [
        "plt.imshow(test_X[0].reshape(28, 28), cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjOlOBlt1TJF",
        "colab_type": "text"
      },
      "source": [
        "Based on the prediction, the label names, and the image, we can tell that the model correctly classified the image as an ankle boot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD-UKdsVNLUQ",
        "colab_type": "text"
      },
      "source": [
        "**2.2 Transfer Learning**\n",
        "\n",
        "Repeat the same task, but this time utilize a pre-trained network for the majority of your model. You should only train the final Dense layer, all other weights should be fixed. You can use whichever pre-trained backbone you like (ResNet, VGG, etc). Report on your modelâ€™s performance on training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe9204z_NNHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT & PREP THE DATA\n",
        "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n",
        "\n",
        "# Convert images into 3 channels\n",
        "train_X=np.dstack([train_X] * 3)\n",
        "test_X=np.dstack([test_X]*3)\n",
        "train_X.shape,test_X.shape\n",
        "\n",
        "# Reshape images as per the tensor format required by tensorflow\n",
        "train_X = train_X.reshape(-1,28,28,3)\n",
        "test_X= test_X.reshape (-1,28,28,3)\n",
        "train_X.shape,test_X.shape\n",
        "\n",
        "# Resize the images to 48x48 for VGG16\n",
        "train_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in train_X])\n",
        "test_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in test_X])\n",
        "train_X.shape, test_X.shape\n",
        "\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "train_X = train_X / 255\n",
        "test_X = test_X / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjHBWp_B_juP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "758d2e0c-cd16-4a1d-f435-a3705f0a45ab"
      },
      "source": [
        "# Converting Labels to one hot encoded format\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "\n",
        "# Splitting train data as train and validation data\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.3, random_state=27)\n",
        "\n",
        "train_X.shape,\n",
        "valid_X.shape,\n",
        "train_label.shape,\n",
        "valid_label.shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h8bVAyw1cz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "309a98d6-6447-4cb2-90fb-46c3f061b3e2"
      },
      "source": [
        "# Preprocess Data \n",
        "train_X = preprocess_input(train_X)\n",
        "valid_X = preprocess_input(valid_X)\n",
        "test_X  = preprocess_input (test_X)\n",
        "\n",
        "#  VGG16 Model\n",
        "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(48, 48, 3))   # use pretrained weights\n",
        "conv_base.summary()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 48, 48, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz0MMuo92OR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "73ce2c87-fe35-44e0-8f2e-f6f79f07beef"
      },
      "source": [
        "# Extracting features\n",
        "train_features = conv_base.predict(np.array(train_X), batch_size=16, verbose=1)\n",
        "test_features = conv_base.predict(np.array(test_X), batch_size=16, verbose=1)\n",
        "val_features = conv_base.predict(np.array(valid_X), batch_size=16, verbose=1)\n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000/42000 [==============================] - 1850s 44ms/step\n",
            "10000/10000 [==============================] - 439s 44ms/step\n",
            "18000/18000 [==============================] - 789s 44ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el1OaXeFBEC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save features \n",
        "np.savez(\"train_features\", train_features, train_label)\n",
        "np.savez(\"test_features\", test_features, test_Y)\n",
        "np.savez(\"val_features\", val_features, valid_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfW58RTgORSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8ad78c6d-561c-48ce-ff4a-7805803d3866"
      },
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(val_features.shape)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1, 1, 512)\n",
            "(10000, 1, 1, 512)\n",
            "(18000, 1, 1, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH9IIqg4N6mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flatten extracted features\n",
        "train_features_flat = np.reshape(train_features, (42000, 1*1*512))\n",
        "test_features_flat = np.reshape(test_features, (10000, 1*1*512))\n",
        "val_features_flat = np.reshape(val_features, (18000, 1*1*512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxei84CLOHWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP02hgtKBHiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_TRAIN_SAMPLES = train_features_flat.shape[0]\n",
        "NB_VALIDATION_SAMPLES = val_features_flat.shape[0]\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_dim=(1*1*512)))       # Densely connected classifier\n",
        "model.add(layers.LeakyReLU(alpha=0.1))                                     # leakyrelu layer\n",
        "model.add(layers.Dense(10, activation='softmax'))                          # dense layer for the number of classes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbM_LKj5O5oM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "611b95a6-729e-4262-f539-ad642f0f24b5"
      },
      "source": [
        "# Incorporate reduced learning and early stopping for callback\n",
        "#reduce_learning = callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.2, patience=2, verbose=1, mode='auto', epsilon=0.0001, cooldown=2, min_lr=0)\n",
        "#early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')\n",
        "#callbacks = [#reduce_learning, \n",
        " #            early_stopping]\n",
        "\n",
        "# Train model\n",
        "#history = model.fit(train_features_flat, train_label, epochs=55, validation_data=(val_features_flat, valid_label), callbacks=callbacks)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')\n",
        "model = model.fit(train_features_flat, train_label, batch_size=125, epochs=125, validation_data=(val_features_flat, valid_label), callbacks=[early_stopping])\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/125\n",
            "42000/42000 [==============================] - 6s 136us/step - loss: 1.7562 - acc: 0.3702 - val_loss: 1.4048 - val_acc: 0.5052\n",
            "Epoch 2/125\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 1.3191 - acc: 0.5232 - val_loss: 1.2143 - val_acc: 0.5588\n",
            "Epoch 3/125\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 1.1580 - acc: 0.5877 - val_loss: 1.1012 - val_acc: 0.6072\n",
            "Epoch 4/125\n",
            "42000/42000 [==============================] - 5s 123us/step - loss: 1.0695 - acc: 0.6205 - val_loss: 1.0910 - val_acc: 0.6443\n",
            "Epoch 5/125\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 1.0049 - acc: 0.6444 - val_loss: 0.9669 - val_acc: 0.6667\n",
            "Epoch 6/125\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 0.9680 - acc: 0.6552 - val_loss: 0.9522 - val_acc: 0.6549\n",
            "Epoch 7/125\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.9362 - acc: 0.6672 - val_loss: 0.9040 - val_acc: 0.6668\n",
            "Epoch 8/125\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.9108 - acc: 0.6743 - val_loss: 0.8940 - val_acc: 0.6800\n",
            "Epoch 9/125\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.8884 - acc: 0.6838 - val_loss: 0.8552 - val_acc: 0.6995\n",
            "Epoch 10/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.8807 - acc: 0.6815 - val_loss: 0.8450 - val_acc: 0.7016\n",
            "Epoch 11/125\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.8619 - acc: 0.6931 - val_loss: 0.8312 - val_acc: 0.7058\n",
            "Epoch 12/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.8536 - acc: 0.6923 - val_loss: 0.8323 - val_acc: 0.6949\n",
            "Epoch 13/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.8416 - acc: 0.6965 - val_loss: 0.8250 - val_acc: 0.7113\n",
            "Epoch 14/125\n",
            "42000/42000 [==============================] - 5s 123us/step - loss: 0.8317 - acc: 0.7014 - val_loss: 0.7986 - val_acc: 0.7155\n",
            "Epoch 15/125\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 0.8238 - acc: 0.7020 - val_loss: 0.8053 - val_acc: 0.7077\n",
            "Epoch 16/125\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 0.8100 - acc: 0.7085 - val_loss: 0.8097 - val_acc: 0.7063\n",
            "Epoch 17/125\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 0.8032 - acc: 0.7111 - val_loss: 0.7693 - val_acc: 0.7263\n",
            "Epoch 18/125\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.7950 - acc: 0.7150 - val_loss: 0.8224 - val_acc: 0.7038\n",
            "Epoch 19/125\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.7933 - acc: 0.7144 - val_loss: 0.7585 - val_acc: 0.7281\n",
            "Epoch 20/125\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.7832 - acc: 0.7177 - val_loss: 0.8143 - val_acc: 0.6996\n",
            "Epoch 21/125\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.7765 - acc: 0.7211 - val_loss: 0.7499 - val_acc: 0.7286\n",
            "Epoch 22/125\n",
            "42000/42000 [==============================] - 5s 117us/step - loss: 0.7764 - acc: 0.7193 - val_loss: 0.7501 - val_acc: 0.7312\n",
            "Epoch 23/125\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.7661 - acc: 0.7245 - val_loss: 0.7652 - val_acc: 0.7210\n",
            "Epoch 24/125\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.7635 - acc: 0.7221 - val_loss: 0.7529 - val_acc: 0.7369\n",
            "Epoch 25/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.7599 - acc: 0.7263 - val_loss: 0.7922 - val_acc: 0.7017\n",
            "Epoch 26/125\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.7527 - acc: 0.7271 - val_loss: 0.7341 - val_acc: 0.7413\n",
            "Epoch 27/125\n",
            "42000/42000 [==============================] - 5s 121us/step - loss: 0.7478 - acc: 0.7295 - val_loss: 0.7292 - val_acc: 0.7401\n",
            "Epoch 28/125\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.7448 - acc: 0.7312 - val_loss: 0.7318 - val_acc: 0.7333\n",
            "Epoch 29/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.7419 - acc: 0.7350 - val_loss: 0.7149 - val_acc: 0.7412\n",
            "Epoch 30/125\n",
            "42000/42000 [==============================] - 5s 116us/step - loss: 0.7389 - acc: 0.7337 - val_loss: 0.7652 - val_acc: 0.7274\n",
            "Epoch 31/125\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 0.7400 - acc: 0.7331 - val_loss: 0.7673 - val_acc: 0.7144\n",
            "Epoch 32/125\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 0.7349 - acc: 0.7349 - val_loss: 0.7016 - val_acc: 0.7506\n",
            "Epoch 33/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.7313 - acc: 0.7361 - val_loss: 0.7126 - val_acc: 0.7456\n",
            "Epoch 34/125\n",
            "42000/42000 [==============================] - 5s 120us/step - loss: 0.7264 - acc: 0.7396 - val_loss: 0.6949 - val_acc: 0.7515\n",
            "Epoch 35/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.7289 - acc: 0.7381 - val_loss: 0.7087 - val_acc: 0.7486\n",
            "Epoch 36/125\n",
            "42000/42000 [==============================] - 5s 119us/step - loss: 0.7196 - acc: 0.7409 - val_loss: 0.7129 - val_acc: 0.7449\n",
            "Epoch 37/125\n",
            "42000/42000 [==============================] - 5s 114us/step - loss: 0.7192 - acc: 0.7408 - val_loss: 0.7596 - val_acc: 0.7167\n",
            "Epoch 38/125\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.7225 - acc: 0.7390 - val_loss: 0.6980 - val_acc: 0.7469\n",
            "Epoch 39/125\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.7198 - acc: 0.7399 - val_loss: 0.7257 - val_acc: 0.7421\n",
            "Epoch 40/125\n",
            "42000/42000 [==============================] - 5s 118us/step - loss: 0.7146 - acc: 0.7401 - val_loss: 0.6988 - val_acc: 0.7522\n",
            "Epoch 41/125\n",
            "42000/42000 [==============================] - 5s 115us/step - loss: 0.7076 - acc: 0.7462 - val_loss: 0.7045 - val_acc: 0.7497\n",
            "Epoch 00041: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erfoSmixS0Nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ec3c010f-8c8c-4848-a7b7-3f285e5fdb1a"
      },
      "source": [
        "# Evaluate\n",
        "def plot_train_history_loss(model):\n",
        "    # summarize history for loss\n",
        "    plt.plot(model.history['loss'])\n",
        "    plt.plot(model.history['val_loss'])\n",
        "    #plt.title('Convolutional Autoencoder Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "plot_train_history_loss(model)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npVxOg0AppVxOg0AppVzu/wOn4VmWvBE4SwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9EVZbR3NOAK",
        "colab_type": "text"
      },
      "source": [
        "###**3. Text Classification**\n",
        "\n",
        "While images contain local spatial correlations and structure, many other datasets contain temporal correlations. Examples include time series and discrete sequences such as text. In this problem, we will tackle the task of text classification in the context of natural language.\n",
        "\n",
        "**Background** In this problem, we will build models that read short text segments (tweets) and identify if one or more specific topics are being discussed. \n",
        "\n",
        "**Dataset** The dataset consists of tweets along with labels for which topics were being referenced in the tweet. Examples of the topics include â€stormsâ€, â€rainâ€, â€hurricaneâ€, â€snowâ€ and so on. Unlike previous classification problems we have encountered, in this dataset, there is not just a single right answer. The labels here are derived from multiple annotators decided how to label each tweet, so a single tweet can be about more than one topic. The label is the\n",
        "fraction of annotations for a given topic, and each row should sum to 1.\n",
        "\n",
        "What Loss function should you use here? Categorical CrossEntropy might work, but with some modification since we donâ€™t have â€hardâ€ labels over the categories. Another option might be sigmoid: for each output category, use a sigmoid to collapse the output to between 0 and 1, but each category output can be roughly independent of the others. In the problems below, feel free to\n",
        "try both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLDb76Zajwmo",
        "colab_type": "text"
      },
      "source": [
        "REFERENCE: https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7jILRtWT_gt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4ea919c6-afbd-4e36-f7e8-80656d5ac997"
      },
      "source": [
        "# IMPORT THE DATA\n",
        "import pandas as pd\n",
        "tweets = open(\"tweets_with_labels.csv\")\n",
        "lines = tweets.readlines()\n",
        "tweets.close()\n",
        "\n",
        "lines = [line.strip('\\n') for line in lines]\n",
        "tweettext = [line.split(\"\\t\") for line in lines]\n",
        "header = tweettext[0]\n",
        "\n",
        "# Check the shape of the data\n",
        "print(len(header))\n",
        "print(len(tweettext))\n",
        "\n",
        "\n",
        "tweettext = [c for c in tweettext[1:] if len(c)==17]\n",
        "print(len(tweettext))\n",
        "\n",
        "tweets = pd.DataFrame(columns=header, data=tweettext)\n",
        "\n",
        "## Rename the columns\n",
        "tweets.rename(columns = {'k1':'clouds'}, inplace = True) \n",
        "tweets.rename(columns = {'k2':'cold'}, inplace = True) \n",
        "tweets.rename(columns = {'k3':'dry'}, inplace = True) \n",
        "tweets.rename(columns = {'k4':'hot'}, inplace = True) \n",
        "tweets.rename(columns = {'k5':'humid'}, inplace = True) \n",
        "tweets.rename(columns = {'k6':'hurricane'}, inplace = True) \n",
        "tweets.rename(columns = {'k7':'icanttell'}, inplace = True) \n",
        "tweets.rename(columns = {'k8':'ice'}, inplace = True) \n",
        "tweets.rename(columns = {'k9':'other'}, inplace = True) \n",
        "tweets.rename(columns = {'k10':'rain'}, inplace = True) \n",
        "tweets.rename(columns = {'k11':'snow'}, inplace = True) \n",
        "tweets.rename(columns = {'k12':'storms'}, inplace = True) \n",
        "tweets.rename(columns = {'k13':'sun'}, inplace = True) \n",
        "tweets.rename(columns = {'k14':'tornado'}, inplace = True) \n",
        "tweets.rename(columns = {'k15':'wind'}, inplace = True) \n",
        "\n",
        "# Check the first 5 rows of data - each row should sum to 1\n",
        "tweets[:5]\n"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "77947\n",
            "77847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clouds</th>\n",
              "      <th>cold</th>\n",
              "      <th>dry</th>\n",
              "      <th>hot</th>\n",
              "      <th>humid</th>\n",
              "      <th>hurricane</th>\n",
              "      <th>icanttell</th>\n",
              "      <th>ice</th>\n",
              "      <th>other</th>\n",
              "      <th>rain</th>\n",
              "      <th>snow</th>\n",
              "      <th>storms</th>\n",
              "      <th>sun</th>\n",
              "      <th>tornado</th>\n",
              "      <th>wind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Jazz for a Rainy Afternoon:  {link}</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>RT: @mention: I love rainy days.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Good Morning Chicago! Time to kick the Windy C...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Preach lol! :) RT @mention: #alliwantis this t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>@mention good morning sunshine</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  id                                              tweet  ... tornado wind\n",
              "0  1                Jazz for a Rainy Afternoon:  {link}  ...       0    0\n",
              "1  2                   RT: @mention: I love rainy days.  ...       0    0\n",
              "2  3  Good Morning Chicago! Time to kick the Windy C...  ...       0    0\n",
              "3  6  Preach lol! :) RT @mention: #alliwantis this t...  ...       0    0\n",
              "4  9                     @mention good morning sunshine  ...       0    0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Yirha_a4lx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e88ff62c-a21d-4e11-ef81-714e94161284"
      },
      "source": [
        "# CLEAN THE DATA\n",
        "\n",
        "# Remove mentions as these shouldnt count as text\n",
        "tweets[\"tweet\"] = tweets[\"tweet\"].apply(lambda x : ' '.join([w for w in x.split() if not w.startswith('@') ])  ) \n",
        "\n",
        "# Split up the text and the labels\n",
        "TEXT = tweets[\"tweet\"].values\n",
        "LABELS = tweets.iloc[:,2:].values\n",
        "\n",
        "# Remove symbols and numbers from text\n",
        "import re\n",
        "TEXT = np.array(list(map(lambda i: re.sub('[^a-zA-Z]', ' ', i), TEXT)))\n",
        "TEXT = np.array(list(map(lambda i: re.sub(r'\\s+', ' ', i), TEXT)))\n",
        "\n",
        "TEXT[:5]"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Jazz for a Rainy Afternoon link ', 'RT I love rainy days ',\n",
              "       'Good Morning Chicago Time to kick the Windy City in the nuts and head back West ',\n",
              "       'Preach lol RT alliwantis this type of weather all the time I live for beautiful days like this minneapolis',\n",
              "       'good morning sunshine'], dtype='<U167')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qnWifv0hk1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85a42799-c16f-40cb-c148-7be484cb4870"
      },
      "source": [
        "# SPLIT 30:70 for TEST/TRAIN\n",
        "TEXT_train, TEXT_test, LABEL_train, LABEL_test = train_test_split(TEXT, \n",
        "                                                                  LABELS, \n",
        "                                                                  test_size=0.30, \n",
        "                                                                  random_state=27)\n",
        "\n",
        "print(TEXT_train.shape,LABEL_train.shape)\n",
        "print(TEXT_test.shape,LABEL_test.shape)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54492,) (54492, 15)\n",
            "(23355,) (23355, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGOg3dySYoli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d48709e5-685b-49b9-9a94-92b00e8f0584"
      },
      "source": [
        "#TOKENIZE TWEETS\n",
        "\n",
        "tk = Tokenizer(num_words=50000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tk.fit_on_texts(TEXT_train)\n",
        "tk.fit_on_texts(TEXT_test)\n",
        "\n",
        "word_index = tk.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "train_tokenized = tk.texts_to_sequences(TEXT_train)\n",
        "test_tokenized = tk.texts_to_sequences(TEXT_test)\n",
        "\n",
        "TEXT_train = pad_sequences(train_tokenized, maxlen = 250)\n",
        "TEXT_test = pad_sequences(test_tokenized, maxlen = 250)\n",
        "\n",
        "print('Shape of Train data tensor:', TEXT_train.shape)\n",
        "print('Shape of Test data tensor:', TEXT_test.shape)\n",
        "\n",
        "TEXT = pad_sequences(sequences, maxlen=500)\n"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 39667 unique tokens.\n",
            "Shape of Train data tensor: (54492, 250)\n",
            "Shape of Test data tensor: (23355, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyDQBfU1f-gi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "4831151d-e3df-4745-f222-d61bceeb9658"
      },
      "source": [
        "## USE GLOVE FOR WORD EMBEDDINGS\n",
        "\n",
        "pip install glove_python\n",
        "\n",
        "from glove import Corpus, Glove"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glove_python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/79/7e7e548dd9dcb741935d031117f4bed133276c2a047aadad42f1552d1771/glove_python-0.1.0.tar.gz (263kB)\n",
            "\r\u001b[K     |â–ˆâ–Ž                              | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–Œ                             | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Š                            | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.3.3)\n",
            "Building wheels for collected packages: glove-python\n",
            "  Building wheel for glove-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python: filename=glove_python-0.1.0-cp36-cp36m-linux_x86_64.whl size=700333 sha256=f34222a778fabefd4e3313a0aee504217693edde0e7f7afbb9ae8304a3bf6270\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/4b/6d/10c0d2ad32c9d9d68beec9694a6f0b6e83ab1662a90a089a4b\n",
            "Successfully built glove-python\n",
            "Installing collected packages: glove-python\n",
            "Successfully installed glove-python-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TjgwqDTNUd9",
        "colab_type": "text"
      },
      "source": [
        "**3.1 RNN**\n",
        "\n",
        "Build and train a Recurrent Neural Network to solve this text classification task. You can use any type of RNN you wish (SimpleRNN, GRU, LSTM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g43JPtS7o9Nm",
        "colab_type": "text"
      },
      "source": [
        "*  The first layer is the embedded layer that uses 100 length vectors to represent each word.\n",
        "\n",
        "*  SpatialDropout1D performs variational dropout in NLP models.\n",
        "\n",
        "*  The next layer is the LSTM layer with 100 memory units.\n",
        "\n",
        "*  The output layer must create 13 output values, one for each class.\n",
        "\n",
        "*  Activation function is softmax for multi-class classification.\n",
        "\n",
        "*  Because it is a multi-class classification problem, categorical_crossentropy is used as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqCHxnp_qP2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import SpatialDropout1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bD-P0lFpMhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "f6b0254d-9625-426a-b618-8743b56cb721"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(50000, 100, input_length=TEXT.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(TEXT_train, \n",
        "                    LABEL_train, \n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.1)\n"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-221-b8b94ee47a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     validation_split=0.1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_4_input to have shape (500,) but got array with shape (250,)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2AXd0LfNVru",
        "colab_type": "text"
      },
      "source": [
        "**3.2 CNN**\n",
        "\n",
        "Build and train a 1D CNN for this text classification task. We recommend you do a character-level convolution (with character embeddings). You might gain some insight and inspiration from these text classification approaches:\n",
        "\n",
        "â€¢ http://www.aclweb.org/anthology/D14-1181\n",
        "\n",
        "â€¢ https://arxiv.org/abs/1702.08568"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwiWA5NwNZS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlLCmCUYNaEm",
        "colab_type": "text"
      },
      "source": [
        "**3.3 Comparison**\n",
        "\n",
        "Be sure to directly compare your two methods with an ROC curve or similar validation method. Donâ€™t forget to create a train-test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTeYMCtONec8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}